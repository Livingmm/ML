{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Êú∫Âô®Â≠¶‰π†ÁöÑÊ¶ÇÁéáÂ∑•ÂÖ∑\n",
    "\n",
    "- [Ë¥ùÂè∂ÊñØÁªüËÆ°Êé®Êñ≠ÔºåÊúÄÂ§ß‰ººÁÑ∂‰º∞ËÆ°Ôºå‰ºòÂåñ](#ball)\n",
    "- [Êú∫Âô®Â≠¶‰π†ÁêÜËÆ∫: ÂÅèÂ∑Æ-ÊñπÂ∑ÆÂàÜËß£ÔºåÊ≥õÂåñ](#bsva)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification versus Regression <a name=\"ClfReg\"></a> \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"../image/ClassificationRegression.png\" width=\"1200\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Supervised Learning <a name=\"sup\"></a>\n",
    "\n",
    "Supervised learning is done using a ground truth, or in other words, we have prior knowledge of what the output values for our samples should be. Therefore, the goal of supervised learning is to learn a function that, given a sample of data and desired outputs, best approximates the relationship between input and output observable in the data\n",
    "\n",
    "A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. \n",
    "\n",
    "An optimal scenario will allow for the algorithm to correctly determine the output values for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a \"reasonable\" way "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The most widely used supervised learning algorithms are:\n",
    "\n",
    "- linear regression\n",
    "\n",
    "- logistic regression\n",
    "\n",
    "- Support Vector Machines\n",
    "\n",
    "- K-nearest neighbor algorithm\n",
    "\n",
    "- Decision trees\n",
    "\n",
    "- Neural Networks (Multilayer perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Unsupervised Learning <a name=\"unSup\"></a>\n",
    "\n",
    "Unsupervised learning does not have labeled outputs,its goal is to infer the natural structure present within a set of data points.\n",
    "\n",
    "Two of the main methods used in unsupervised learning are principal component and cluster analysis. \n",
    "\n",
    "Cluster analysis is used in unsupervised learning to group, or segment, datasets with shared attributes in order to extrapolate algorithmic relationships. \n",
    "\n",
    "Cluster analysis groups the data that has not been labelled, classified or categorized. Instead of responding to feedback, cluster analysis identifies commonalities in the data and reacts based on the presence or absence of such commonalities in each new piece of data. \n",
    "\n",
    "This approach can also detect anomalous data points that do not fit into either group. So called anomaly detection can be used to detect bamk fraud, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ë¥ùÂè∂ÊñØÁªüËÆ°Êé®Êñ≠ÔºåÊúÄÂ§ß‰ººÁÑ∂‰º∞ËÆ°Ôºå‰ºòÂåñ<a name=\"ball\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In machine learning we use a model to describe the process that results in the data that are observed. \n",
    "\n",
    "For example, we may use a linear model to predict the revenue that will be generated for a company depending on how much they may spend on advertising (this would be an example of linear regression). \n",
    "\n",
    "For a linear model we can write this as \n",
    "\\begin{equation*}\n",
    "y = a + bx\n",
    "\\end{equation*}\n",
    "\n",
    "In this example $x$ could represent the advertising spending and $y$ might be the revenue generated. $a$ and $b$ are parameters for this model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Maximum Likelihood Estimation\n",
    "\n",
    "\n",
    "**Maximum likelihood estimation** is a method that determines values for the parameters of a model. \n",
    "\n",
    "The parameter values are found such that they maximise the likelihood that the process described by the model produced the data that were actually observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Empirical Risk Minimizer\n",
    "\\begin{equation*}\n",
    "\\hat{f_n} = arg \\min_{f}\\frac{1}{n}\\sum_{i=1}^n\\left(f(X_i)-y_i\\right)^2\n",
    "\\end{equation*}\n",
    "\n",
    "For a linear model\n",
    "\\begin{equation*}\n",
    "f(X) = X\\beta  + \\epsilon\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{\\beta} &= arg \\min_{\\beta}\\frac{1}{n}\\sum_{i=1}^n\\left(X_i\\beta-Y_i\\right)^2 \\\\\n",
    "&= arg \\min_{\\beta}\\frac{1}{n}\\left(A\\beta-Y\\right)^T\\left(A\\beta-Y\\right) \\\\\n",
    "&= (A^T A)^{‚àí1}A^T Y\n",
    "\\end{align*}\n",
    "where \n",
    "\\begin{align*}\n",
    "A &= \\begin{bmatrix}\n",
    "  X_1^{(1)} & \\cdots & X_1^{(p)} \\\\\n",
    "  \\vdots & \\ddots  & \\vdots  \\\\\n",
    "  X_n^{(1)} & \\cdots & X_n^{(p)}  \\end{bmatrix} \\\\\n",
    "Y &= \\begin{bmatrix}\n",
    "  Y_1 \\\\\n",
    "  \\vdots   \\\\\n",
    "  Y_n \\end{bmatrix} \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Probabilistic Interpretation: MLE\n",
    "\n",
    "Intuition: Signal plus (zero-mean) Noise model\n",
    "For a linear model\n",
    "\\begin{equation*}\n",
    "Y = X\\beta^* + \\epsilon \\quad\\quad\\quad \\epsilon \\sim N(0, \\sigma^2 I)\n",
    "\\end{equation*}    \n",
    "\n",
    "\\begin{equation*}\n",
    "Y \\sim N(X\\beta^*, \\sigma^2 I)\n",
    "\\end{equation*}    \n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{\\beta_{\\text{MLE}}} &= arg \\max_\\beta \\log p\\left(\\left\\{(X_i,Y_i)\\right\\}_{i=1}^n | \\beta, \\sigma^2\\right) \\\\\n",
    "&= arg \\min_{\\beta} \\sum_{i=1}^n\\left(X_i\\beta-Y_i\\right)^2 = \\hat{\\beta}\n",
    "\\end{align*}    \n",
    "\n",
    "\n",
    "Least Square Estimate is the same as Maximum Likelihood Estimate under a\n",
    "Gaussian model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes‚Äô Theorem\n",
    "\n",
    "It allows us to use some knowledge or belief that we already have (commonly known as the prior) to help us calculate the probability of a related event.\n",
    "\\begin{equation*}\n",
    "P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\n",
    "\\end{equation*}\n",
    "where $A$ and $B$ are events, $P(A|B)$ is the conditional probability that event $A$ occurs given that event $B$ has already occurred ($P(B|A)$ has the same meaning but with the roles of $A$ and $B$ reversed) and $P(A)$ and $P(B)$ are the marginal probabilities of event $A$ and event $B$ occurring respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayesian inference\n",
    "\n",
    "**Bayesian inference** is just the process of deducing properties about a population or probability distribution from data using Bayes‚Äôtheorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let us use $\\theta$ to represents the set of model parameters. To estimate the parameter values of a Gaussian distribution then $\\theta$ represents both the mean, $\\mu$ and the standard deviation, $\\sigma$ (written mathematically as $\\theta = \\{\\mu, \\sigma\\}$).\n",
    "The data would be $X = \\{X_1, X_2, ‚Ä¶, X_n\\}$, i.e. the set of observations that we have. \n",
    "\n",
    "So now Bayes‚Äô theorem in model form is written as:\n",
    "\\begin{equation*}\n",
    "P(\\theta|X) = \\frac{P(X|\\theta)P(\\theta)}{P(X)}\n",
    "\\end{equation*}\n",
    "\n",
    "- $P(\\theta)$ is the prior distribution. It represents our beliefs about the true value of the parameters, \n",
    "- $P(\\theta|data)$ on the left hand side is known as the posterior distribution. This is the distribution representing our belief about the parameter values after we have calculated everything on the right hand side taking the observed data into account.\n",
    "- $P(data|\\theta)$ is the likelihood distribution. Sometimes it's written as $L(data;\\theta)$.\n",
    "- $P(data)$ is acting as the normalising constant so that the resulting posterior distribution is a true probability distribution. The sum of the distribution (or integral in case of a continuous distribution) is equal to 1.\n",
    "\n",
    "Therefore we can calculate the posterior distribution of our parameters using our prior beliefs updated with our likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In some cases only care about where the peak of the distribution occurs, regardless of whether the distribution is normalised or not. In this case the model form of Bayes' theorem as:\n",
    "\\begin{equation*}\n",
    "P(\\theta|data) \\propto P(data|\\theta)P(\\theta)\n",
    "\\end{equation*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bayesian inference requires calculating the product of two distributions. The Gaussian distribution has a particular property that makes it easy to work with. Its conjugate to itself with respect to a Gaussian likelihood function. This means that if we multiply a Gaussian prior distribution with a Gaussian likelihood function, We'll get a Gaussian posterior function. \n",
    "\n",
    "The fact that the posterior and prior are both from the same distribution family (they are both Gaussians) means that they are called conjugate distributions. In this case the prior distribution is known as a conjugate prior.\n",
    "\n",
    "In some cases we can‚Äôt just pick the prior or likelihood in such a way to make it easy to calculate the posterior distribution. Sometimes the likelihood and/or the prior distribution can look horrendous and calculating the posterior by hand is not easy or possible. In these cases we can use different methods to calculate the posterior distribution. One of the most common ways is by using a technique called Markov Chain Monte Carlo methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One of the great things about Bayesian inference is that you don‚Äôt need lots of data to use it. 1 observation is enough to update the prior. In fact, the Bayesian framework allows you to update your beliefs iteratively in realtime as data comes in. It works as follows: you have a prior belief about something (e.g. the value of a parameter) and then you receive some data. You can update your beliefs by calculating the posterior distribution like we did above. Afterwards, we get even more data come in. So our posterior becomes the new prior. We can update the new prior with the likelihood derived from the new data and again we get a new posterior. This cycle can continue indefinitely so you‚Äôre continuously updating your beliefs.\n",
    "\n",
    "The Kalman filter (and it‚Äôs variants) is a great example of this. It‚Äôs used in many scenarios, but possibly the most high profile in data science are its applications to self driving cars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayesian inference example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Bayesian Inference has three steps:\n",
    "\n",
    "- Step 1. **Prior** Choose a PDF to model your parameter $\\theta$, aka the prior distribution $P(\\theta)$. This is your best guess about parameters before seeing the data $X$.\n",
    "- Step 2. **Likelihood** Choose a PDF for $P(X|\\theta)$. Basically you are modeling how the data $X$ will look like given the parameter $\\theta$.\n",
    "- Step 3. **Posterior** Calculate the posterior distribution $P(\\theta|X)$ and pick the $\\theta$ that has the highest $P(\\theta|X)$.\n",
    "\n",
    "And the posterior becomes the new prior. Repeat step 3 as you get more data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_mu=0.2855, data_sigma=0.0039\n",
      "post_mu=0.2844, post_sigma=0.0017\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "prior_mu = 0.25\n",
    "prior_sigma = 0.01\n",
    "\n",
    "num_data = 5\n",
    "np.random.RandomState(seed=20200505)\n",
    "X_data = stats.norm.rvs(loc=0.3, scale=0.02, size=num_data) # Random variates.\n",
    "data_mu = X_data.mean()\n",
    "data_sigma = X_data.std()\n",
    "print(\"data_mu=%.4f, data_sigma=%.4f\"%(data_mu, data_sigma))\n",
    "\n",
    "post_mu = ((prior_mu/prior_sigma**2) + ((num_data * data_mu)/data_sigma**2))/((1.0/prior_sigma**2) + (num_data/data_sigma**2))\n",
    "post_sigma = np.sqrt(1.0/((1.0/prior_sigma**2) + (num_data/data_sigma**2)))\n",
    "print(\"post_mu=%.4f, post_sigma=%.4f\"%(post_mu, post_sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x_range = np.linspace(0.2, 0.4, 500) # to center plot on posterior\n",
    "p_prior = stats.norm.pdf(x=x_range, loc=prior_mu, scale=prior_sigma)\n",
    "p_lik   = stats.norm.pdf(x=x_range, loc=data_mu, scale=data_sigma)\n",
    "p_post  = stats.norm.pdf(x=x_range, loc=post_mu, scale=post_sigma)\n",
    "\n",
    "figure_bayesNorm, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(x_range, p_prior, label=\"prior\")\n",
    "ax.plot(x_range, p_lik, label=\"likelihood\")\n",
    "ax.plot(x_range, p_post, label=\"posterior\")\n",
    "ax.hist(X_data, density=True, histtype='stepfilled', alpha=0.3, label=\"data\")\n",
    "plt.ylabel('Density', fontsize=16)\n",
    "ax.legend(loc='upper left', fontsize=16)\n",
    "\n",
    "#plt.show()\n",
    "figure_bayesNorm.savefig('../image/figure_bayesNorm.png') # save the figure to file\n",
    "plt.close(figure_bayesNorm) # close the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<img src=\"../image/figure_bayesNorm.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Maximum A Posteriori estimation (MAP).\n",
    "\n",
    "\n",
    "- Notice the width of the bell curves in prior/likelihood has shrunk in the posterior. Because we incorporated more information through sampling, the range of possible parameters is now narrower.\n",
    "- The more data you gather, the graph of the posterior will look more like that of the likelihood and less like that of the prior. In other words, as you get more data, the original prior distribution matters less.\n",
    "- Finally, we pick $\\theta$ that gives the highest posterior computed by numerical optimization, such as the Gradient Descent or newton method. This whole iterative procedure is called **Maximum A Posteriori estimation (MAP)**.\n",
    "\n",
    "Maximum likelihood estimation (MLE) is just a special case of MAP with a uniform prior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Definition\n",
    "\n",
    "A mathematical optimization problem, has the form\n",
    "\\begin{align}\n",
    "\\text{minimize} \\quad &f_0(x) \\\\ \n",
    "\\text{subject to} \\quad  &f_i(x) \\leq b_i, \\quad i = 1,...,m.\n",
    "\\end{align}\n",
    "\n",
    "Here the vector $x = (x_1,...,x_n)$ is the optimization variable of the problem, the function $f_0 : R^n ‚Üí R$ is the objective function, the functions $f_i : R^n ‚Üí R, i = 1,...,m$, are the (inequality) constraint functions, and the constants $b_1,...,b_m$ are the bounds for the constraints.\n",
    "\n",
    "Obviousely, maximization of function $f_0(x)$ can be achieved by minimizing the negative of the function: $-f_0(x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Optimal Solution $x^*$\n",
    "\n",
    "If vector $x^*$ has the smallest objective value among all vectors that satisfy the constraints: for any $z$ with $f_1(z) \\leq b_1, \\dots, f_m(z) \\leq b_m$, we have\n",
    "\n",
    "\\begin{equation}\n",
    "f_0(z) \\geq f_0(x^*)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Application Example 1\n",
    "\n",
    "In portfolio optimization, one seek the best way to invest some capital in a set of $n$ assets. \n",
    "\n",
    "- The variable $x_i$ represents the investment in the $i$th asset, so the vector $x \\in R^n$ describes the overall portfolio allocation across the set of assets. \n",
    "\n",
    "- The constraints might represent a limit on the budget (i.e., a limit on the total amount to be invested), the requirement that investments are nonnegative (assuming short positions are not allowed), and a minimum acceptable value of expected return for the whole portfolio. \n",
    "\n",
    "- The objective or cost function might be a measure of the overall risk or variance of the portfolio return. \n",
    "\n",
    "The optimization problem corresponds to choosing a portfolio allocation that minimizes risk, among all possible allocations that meet the firm requirements. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cvxpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e8168c1615eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcvxpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Problem data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cvxpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "# Problem data.\n",
    "n = 4\n",
    "np.random.seed(1)\n",
    "Sigma = np.array([[ 4e-2,  6e-3, -4e-3,   0.0 ],\n",
    "                 [ 6e-3,  1e-2,  0.0,    0.0 ],\n",
    "                 [-4e-3,  0.0,   2.5e-3, 0.0 ],\n",
    "                 [ 0.0,   0.0,   0.0,    0.0 ]])\n",
    "pbar = np.array([.12, .10, .07, .03])\n",
    "\n",
    "# Construct the problem.\n",
    "w = cp.Variable(n)\n",
    "ret = pbar*w \n",
    "risk = cp.quad_form(w, Sigma)\n",
    "gamma = cp.Parameter(nonneg=True)\n",
    "objective = cp.Maximize(ret - gamma*gamma*risk)\n",
    "constraints = [cp.sum(w) == 1, w >= 0]\n",
    "prob = cp.Problem(objective, constraints)\n",
    "\n",
    "N = 100\n",
    "w_values = np.zeros((N,n))\n",
    "risk_data = np.zeros(N)\n",
    "ret_data = np.zeros(N)\n",
    "for i in range(N):\n",
    "    gamma.value = 10**(5.0*i/N-1.0)\n",
    "\n",
    "    # The optimal objective value is returned by `prob.solve()`.\n",
    "    result = prob.solve()\n",
    "    # The optimal value for w is stored in `w.value`.\n",
    "    w_values[i] = w.value\n",
    "    risk_data[i] = cp.sqrt(risk).value\n",
    "    ret_data[i] = ret.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure_riskret, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(risk_data, ret_data)\n",
    "ax.set_xlabel('standard deviation')\n",
    "ax.set_ylabel('expected return')\n",
    "ax.axis([0, 0.2, 0, 0.15])\n",
    "ax.set_title('Risk-return trade-off curve')\n",
    "ax.set_yticks([0.00, 0.05, 0.10, 0.15])\n",
    "\n",
    "#plt.show()\n",
    "figure_riskret.savefig('../image/figure_riskret.png') # save the figure to file\n",
    "plt.close(figure_riskret) # close the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Optimal allocations\n",
    "<img src=\"../image/figure_riskret.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "figure_optalloc, ax = plt.subplots(figsize=(8, 6))    \n",
    "c1 = np.array([ w[0] for w in w_values ])\n",
    "c2 = np.array([ w[0] + w[1] for w in w_values ])\n",
    "c3 = np.array([ w[0] + w[1] + w[2] for w in w_values ])\n",
    "c4 = np.array([ w[0] + w[1] + w[2] + w[3] for w in w_values ])\n",
    "ax.fill(risk_data + [.20], c1 + [0.0], facecolor = '#F0F0F0')\n",
    "ax.fill(risk_data[-1::-1] + risk_data, c2[-1::-1] + c1,\n",
    "        facecolor = '#D0D0D0')\n",
    "ax.fill(risk_data[-1::-1] + risk_data, c3[-1::-1] + c2,\n",
    "        facecolor = '#F0F0F0')\n",
    "ax.fill(risk_data[-1::-1] + risk_data, c4[-1::-1] + c3,\n",
    "        facecolor = '#D0D0D0')\n",
    "ax.axis([0.0, 0.2, 0.0, 1.0])\n",
    "ax.set_xlabel('standard deviation', fontsize=16)\n",
    "ax.set_ylabel('allocation', fontsize=16)\n",
    "ax.text(.15,.5,'w1', fontsize=16)\n",
    "ax.text(.10,.7,'w2', fontsize=16)\n",
    "ax.text(.05,.7,'w3', fontsize=16)\n",
    "ax.text(.01,.7,'w4', fontsize=16)\n",
    "ax.set_title('Optimal allocations', fontsize=16)\n",
    "\n",
    "#plt.show()\n",
    "figure_optalloc.savefig('../image/figure_optalloc.png') # save the figure to file\n",
    "plt.close(figure_optalloc) # close the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Optimal allocations\n",
    "<img src=\"../image/figure_optalloc.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Application Example 2\n",
    "\n",
    "In data model fitting, the task is to find a model, from a family of potential models, that best fits some observed data and prior information. \n",
    "\n",
    "- The variables are the parameters in the model\n",
    "\n",
    "- The constraints can represent prior information or required limits on the parameters (such as nonnegativity).\n",
    "\n",
    "- The objective function might be a measure of misfit or prediction error between the observed data and the values predicted by the model, or a statistical measure of the unlikeliness or implausibility of the parameter values. \n",
    "\n",
    "The optimization problem is to find the model parameter values that are consistent with the prior information, and give the smallest misfit or prediction error with the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear Optimization\n",
    "\n",
    "The optimization problem is called a linear program if the objective and constraint functions $f_0,\\dots,f_m$ are linear, i.e., satisfy\n",
    "\\begin{equation}\n",
    "f_i(\\alpha x + \\beta y) = \\alpha f_i(x) + \\beta f_i(y)\n",
    "\\end{equation}\n",
    "for all $x, y \\in R^n$ and all $\\alpha, \\beta \\in R$. If the optimization problem is not linear, it is called a nonlinear program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convex Optimization\n",
    "\n",
    "If the objective and constraint functions are convex, which means they satisfy the inequality \n",
    "\\begin{equation}\n",
    "f_i(\\alpha x + \\beta y) \\leq \\alpha f_i(x) + \\beta f_i(y)\n",
    "\\end{equation}\n",
    "\n",
    "for all $x, y \\in R^n$ and all $\\alpha, \\beta \\in R$ with $\\alpha + \\beta = 1$, $\\alpha \\geq 0$, $\\beta \\geq 0$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def func(x):\n",
    "    f  = 5 + x*x*np.exp(0.1*x)\n",
    "    return f\n",
    "\n",
    "x  = np.arange(-4, 4, 0.01)\n",
    "f = func(x)\n",
    "\n",
    "a = -1\n",
    "b = 3\n",
    "alpha = 0.4\n",
    "sx = np.array([a, a*alpha+(1-alpha)*b, b])\n",
    "sl = np.array([func(a), func(a)*alpha+(1-alpha)*func(b), func(b)])\n",
    "sf = func(sx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "figure_convexfunc, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(x, f)\n",
    "ax.set_title('Convex Fuction')\n",
    "ax.set_xlabel('x', fontsize=20)\n",
    "ax.set_ylabel('f(x)', fontsize=20)\n",
    "\n",
    "ax.plot(sx, sl, c='red')\n",
    "ax.scatter(sx, sf)\n",
    "ax.scatter(sx, sl)\n",
    "\n",
    "ax.text(sx[0]-0.5, sf[0]-1.4, r'$f(x)$', fontsize=16)\n",
    "ax.annotate(r'$f(\\alpha x + (1-\\alpha)y)$', xy=(sx[1], sf[1]), xytext=(sx[1]+0.5, sf[1]-1.2), fontsize=15,\n",
    "           arrowprops=dict(arrowstyle=\"->\",facecolor='black'))\n",
    "ax.text(sx[2]+0.1, sf[2]-1.2, r'$f(y)$', fontsize=16)\n",
    "ax.annotate(r'$\\alpha f(x) + (1-\\alpha)f(y)$', xy=(sx[1], sl[1]), xytext=(sx[1]-3.1, sl[1]+0.2), fontsize=15, \n",
    "            arrowprops=dict(arrowstyle=\"->\",facecolor='black'))\n",
    "\n",
    "#plt.show()\n",
    "figure_convexfunc.savefig('../image/figure_convexfunc.png') # save the figure to file\n",
    "plt.close(figure_convexfunc) # close the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The Convex function\n",
    "<img src=\"../image/figure_convexfunc.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Least-squares problems\n",
    "\n",
    "A least-squares problem is an optimization problem with no constraints (i.e., $m = 0$) and an objective which is a sum of squares of terms of the form $a^T_i x‚àíb_i$: \n",
    "\\begin{equation}\n",
    "\\text{minimize}\\quad f_0(x) = \\parallel Ax ‚àíb \\parallel ^2_2 =\\sum^k_{i=1}(a^T_i x ‚àí b_i)^2.\n",
    "\\end{equation}\n",
    "Here $A \\in R^{k\\times n}$ (with $k \\geq n$), $a^T_i$ are the rows of $A$, and the vector $x \\in R^n$ is the optimization variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solving least-squares problems\n",
    "\n",
    "The solution of a least-squares problem can be reduced to solving a set of linear equations, $(A^TA)x = A^Tb$,\n",
    "so we have the analytical solution $x = (A^TA)^{‚àí1}A^Tb$. \n",
    "\n",
    "For least-squares problems we have good algorithms (and software implementations) for solving the problem to high accuracy, with very high reliability. The least-squares problem can be solved in a time approximately proportional to $n^2k$, with a known constant. \n",
    "\n",
    "In many cases we can solve even larger least-squares problems, by exploiting some special structure in the coeÔ¨Écient matrix A. For example, that the matrix A is sparse, which means that it has far fewer than $kn$ nonzero entries. By exploiting sparsity, we can usually solve the least-squares problem much faster than order $n^2k$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear programming\n",
    "Another important class of optimization problems is linear programming, in which the objective and all constraint functions are linear:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{minimize}\\quad &c^T x \\\\\n",
    "\\text{subject to}\\quad &a^T_i x \\leq b_i, \\quad i = 1,\\dots,m.\n",
    "\\end{align}\n",
    "\n",
    "Here the vectors $c,a_1,\\dots,a_m \\in R^n$ and scalars $b_1,\\dots,b_m \\in R$ are problem parameters that specify the objective and constraint functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solving linear programs\n",
    "There is no simple analytical formula for the solution of a linear program (as there is for a least-squares problem), but there are a variety of very eÔ¨Äective methods for solving them, including simplex method, and interiorpoint methods. \n",
    "\n",
    "The complexity in practice is order $n^2m$ (assuming $m \\geq n$) but with a constant that is less well characterized than for least-squares. \n",
    "\n",
    "Some problem can be converted to a linear program, for example, the Cheyshev approximation problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Chebyshev approximation problem\n",
    "\n",
    "Instead of squared error, the problem use the absolute error:\n",
    "\\begin{equation}\n",
    "\\text{minimize}\\quad\\quad max_{i=1,\\dots,k} |a^T_i x ‚àí b_i|\n",
    "\\end{equation}\n",
    "Here $x \\in R^n$ is the variable, and $a_1,\\dots,a_k \\in R^n$, $b_1,\\dots,b_k \\in R$ are parameters that specify the problem instance.\n",
    "\n",
    "The Chebyshev approximation problem can be solved by solving the linear program\n",
    "\\begin{align}\n",
    "\\text{minimize}\\quad &t \\\\\n",
    "\\text{subject to} \\quad &a^T_i x ‚àí t \\leq b_i, \\quad i = 1,\\dots,k \\\\\n",
    "                        &‚àía^T_i x ‚àí t \\leq ‚àíb_i, \\quad i = 1,\\dots,k\n",
    "\\end{align}\n",
    "with variables $x \\in R^n$ and $t \\in R$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solving convex optimization problems\n",
    "\n",
    "There is in general no analytical formula for the solution of convex optimization problems, but (as with linear programming problems) there are very eÔ¨Äective methods for solving them. Interior-point methods work very well in practice, and in some cases can be proved to solve the problem to a speciÔ¨Åed accuracy with a number of operations that does not exceed a polynomial of the problem dimensions. \n",
    "\n",
    "The interior-point methods can solve the problem in a number of steps or iterations that is almost always in the range between 10 and 100. Ignoring any structure in the problem (such as sparsity), each step requires on the order of \n",
    "\\begin{equation}\n",
    "max\\{n^3,n^2m,F\\}\n",
    "\\end{equation}\n",
    "operations, where $F$ is the cost of evaluating the Ô¨Årst and second derivatives of the objective and constraint functions $f_0,\\dots,f_m$\n",
    "\n",
    "The least-squares problem and linear programming problem are both special cases of the general convex optimization problem.\n",
    "However, recognizing a least-squares problem is straight forward, recognizing a convex function can be difficult. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Nonlinear optimization\n",
    "Nonlinear optimization (or nonlinear programming) is the term used to describe an optimization problem when the objective or constraint functions are not linear, but not known to be convex.\n",
    "\n",
    "There are no eÔ¨Äective methods for solving the general nonlinear programming problem. Methods for the general nonlinear programming problem therefore take several diÔ¨Äerent approaches, each of which involves some compromise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Local optimization\n",
    "\n",
    "In local optimization, the compromise is to give up seeking the optimal x, which minimizes the objective over all feasible points. Instead we seek a point that is only locally optimal, which means that it minimizes the objective function among feasible points that are near it, but is not guaranteed to have a lower objective value than all other feasible points. \n",
    "\n",
    "Local optimization methods can be fast, can handle large-scale problems, and are widely applicable, since they only require differentiability of the objective and constraint functions. As a result, local optimization methods are widely used in applications where there is value in finding a good point, if not the very best.\n",
    "\n",
    "Using a local optimization method is trickier than solving a least-squares problem, linear program, or convex optimization problem. It involves experimenting with the choice of algorithm, adjusting algorithm parameters, and finding a good enough initial guess or a method for producing a good enough initial guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient Descent\n",
    "Gradient descent is an iterative optimization algorithm for finding the minimum of a cost function. To find a local minimum of a function using gradient descent, one takes steps proportional to the negative of the gradient (or approximate gradient) of the function at the current point.\n",
    "\n",
    "\\begin{equation*}\n",
    "x_{i+1} = x_i - \\gamma\\left ((\\nabla f)(x_i) \\right )^T\n",
    "\\end{equation*}\n",
    "\n",
    "Picture below illustrates the steps we take going down of the hill to find local minimum. The direction of the step is defined by derivative of the cost function in current point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum occurs at 1.9995531681185024\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.1 # step size multiplier\n",
    "precision = 0.001\n",
    "max_iters = 100 # maximum number of iterations\n",
    "\n",
    "f = lambda x: 1/4*x**4-1/3*x**3-x**2+3\n",
    "df = lambda x: x**3 - x**2 - 2*x\n",
    "\n",
    "cur_x = 0.1 # The algorithm starts at x=0.1\n",
    "iters = 0 #iteration counter\n",
    "previous_step_size = 1 \n",
    "\n",
    "xlist = [cur_x]\n",
    "flist = [f(cur_x)]\n",
    "while previous_step_size > precision and iters < max_iters:\n",
    "    prev_x = cur_x\n",
    "    cur_x -= gamma * df(prev_x)\n",
    "    previous_step_size = abs(cur_x - prev_x)\n",
    "    iters += 1\n",
    "    xlist.append(cur_x)\n",
    "    flist.append(f(cur_x))\n",
    "\n",
    "print(\"The minimum occurs at\", cur_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x  = np.arange(-2, 3, 0.001)\n",
    "y = f(x)\n",
    "figure_grad_des, ax = plt.subplots(figsize=(12, 9))\n",
    "ax.set_title(r'$f(x)=\\frac{1}{4}x^4-\\frac{1}{3}x^3-x^2+3$', fontsize=16)\n",
    "ax.plot(x, y)\n",
    "ax.plot(xlist, flist, '-rv')\n",
    "ax.annotate(r'start at $x=%0.1f$' % xlist[0], xy=(xlist[0], flist[0]), xycoords='data',\n",
    "            xytext=(xlist[0]+0.1, flist[0]+0.2), textcoords='data', fontsize=16,\n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle=\"arc3,rad=.2\"))\n",
    "ax.annotate(r'Minimum at $x=%0.1f$' % xlist[-1], xy=(xlist[-1], flist[-1]), xycoords='data', \n",
    "            xytext=(xlist[-1]-1.5, flist[-1]-0.1), textcoords='data', fontsize=16,\n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle=\"arc3,rad=.2\"))\n",
    "\n",
    "#plt.show()\n",
    "figure_grad_des.savefig('../image/figure_grad_des.png') \n",
    "plt.close(figure_grad_des)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gradient Descent\n",
    "\n",
    "- start at initial point  ùë•=0.1 ,\n",
    "- move along the negative direction of the gradient,\n",
    "- step size is proportional to the magnitude of the gradient.\n",
    "\n",
    "<img src=\"../image/figure_grad_des.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The local minimum occurs at -0.999389360392916\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.2 # step size multiplier\n",
    "precision = 0.001\n",
    "max_iters = 100 # maximum number of iterations\n",
    "\n",
    "f = lambda x: 1/4*x**4-1/3*x**3-x**2+3\n",
    "df = lambda x: x**3 - x**2 - 2*x\n",
    "\n",
    "cur_x = -0.1 # The algorithm starts at x=-0.1\n",
    "iters = 0 #iteration counter\n",
    "previous_step_size = 1 \n",
    "\n",
    "xlist = [cur_x]\n",
    "flist = [f(cur_x)]\n",
    "while previous_step_size > precision and iters < max_iters:\n",
    "    prev_x = cur_x\n",
    "    cur_x -= gamma * df(prev_x)\n",
    "    previous_step_size = abs(cur_x - prev_x)\n",
    "    iters+=1\n",
    "    xlist.append(cur_x)\n",
    "    flist.append(f(cur_x))\n",
    "\n",
    "print(\"The local minimum occurs at\", cur_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x  = np.arange(-2, 3, 0.001)\n",
    "y = f(x)\n",
    "figure_grad_des_loc, ax = plt.subplots(figsize=(12, 9))\n",
    "ax.set_title(r'$f(x)=\\frac{1}{4}x^4-\\frac{1}{3}x^3-x^2+3$', fontsize=16)\n",
    "ax.plot(x, y)\n",
    "ax.plot(xlist, flist, '-r<')\n",
    "ax.annotate(r'start at $x=%0.1f$' % xlist[0], xy=(xlist[0], flist[0]), xycoords='data',\n",
    "            xytext=(xlist[0]+0.1, flist[0]+0.2), textcoords='data', fontsize=16,\n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle=\"arc3,rad=.2\"))\n",
    "ax.annotate(r'Local minimum at $x=%0.1f$' % xlist[-1], xy=(xlist[-1], flist[-1]), xycoords='data', \n",
    "            xytext=(xlist[-1]-1, flist[-1]-0.5), textcoords='data', fontsize=16,\n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle=\"arc3,rad=.2\"))\n",
    "\n",
    "#plt.show()\n",
    "figure_grad_des_loc.savefig('../image/figure_grad_des_loc.png') \n",
    "plt.close(figure_grad_des_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Start at initial point ùë•=-0.1,\n",
    "\n",
    "<img src=\"../image/figure_grad_des_loc.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "gamma = 1 # a large step size multiplier\n",
    "precision = 0.001\n",
    "max_iters = 3 # maximum number of iterations\n",
    "\n",
    "f = lambda x: 1/4*x**4-1/3*x**3-x**2+3\n",
    "df = lambda x: x**3 - x**2 - 2*x\n",
    "\n",
    "cur_x = 0.1 # The algorithm starts at x=-0.1\n",
    "iters = 0 #iteration counter\n",
    "previous_step_size = 1 \n",
    "\n",
    "xlist = [cur_x]\n",
    "flist = [f(cur_x)]\n",
    "while previous_step_size > precision and iters < max_iters:\n",
    "    prev_x = cur_x\n",
    "    cur_x -= gamma * df(prev_x)\n",
    "    previous_step_size = abs(cur_x - prev_x)\n",
    "    iters+=1\n",
    "    xlist.append(cur_x)\n",
    "    flist.append(f(cur_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x  = np.arange(-2, 3, 0.001)\n",
    "y = f(x)\n",
    "figure_grad_des_largestep, ax = plt.subplots(figsize=(12, 9))\n",
    "ax.set_title(r'$f(x)=\\frac{1}{4}x^4-\\frac{1}{3}x^3-x^2+3$', fontsize=16)\n",
    "ax.plot(x, y)\n",
    "ax.plot(xlist, flist, '-r<')\n",
    "ax.annotate(r'start at $x=%0.1f$' % xlist[0], xy=(xlist[0], flist[0]), xycoords='data',\n",
    "            xytext=(xlist[0]+0.1, flist[0]+0.2), textcoords='data', fontsize=16,\n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle=\"arc3,rad=.2\"))\n",
    "\n",
    "#plt.show()\n",
    "figure_grad_des_largestep.savefig('../image/figure_grad_des_largestep.png') \n",
    "plt.close(figure_grad_des_largestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With a large step size multiplier,\n",
    "\n",
    "<img src=\"../image/figure_grad_des_largestep.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Adaptive gradient methods \n",
    "\n",
    "Adaptive gradient methods rescale the step-size at each iteration, depending\n",
    "on local properties of the function:\n",
    "- When the function value increases after a gradient step, the step-size\n",
    "was too large. Undo the step and decrease the step-size.\n",
    "- When the function value decreases the step could have been larger. Try\n",
    "to increase the step-size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Global optimization\n",
    "In global optimization, the true global solution of the optimization problem is found; the compromise is efficiency. The worst-case complexity of global optimization methods grows exponentially with the problem sizes n and m.\n",
    "\n",
    "Global optimization is used for problems with a small number of variables, where computing time is not critical, and the value of Ô¨Ånding the true global solution is very high. \n",
    "\n",
    "For example, for daily fitting of models of financial market, if one day's fit is significantly different from past fits, is it because the fit finds another local minimum, or because the market has a true regime change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Role of convex optimization in nonconvex problems\n",
    "\n",
    "- Initialization for local optimization: Find a convex approximate formulation of the problem. By solving this approximate problem, which can be done easily and without an initial guess, we obtain the exact solution to the approximate convex problem. This point is then used as the starting point for a local optimization method, applied to the original nonconvex problem.\n",
    "\n",
    "\n",
    "- Bounds for global optimization: In relaxation, each nonconvex constraint is replaced with a looser, but convex, constraint. In Lagrangian relaxation, the Lagrangian dual problem is solved. It provides a lower bound on the optimal value of the nonconvex problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Êú∫Âô®Â≠¶‰π†ÁêÜËÆ∫: ÂÅèÂ∑Æ-ÊñπÂ∑ÆÂàÜËß£ÔºåÊ≥õÂåñ<a name=\"bsva\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bias versus variance <a name=\"BiaVar\"></a>\n",
    "\n",
    "Imagine that we have available several different, but equally good, training data sets. \n",
    "\n",
    "A learning algorithm is **biased** for a particular input $x$ if, when trained on each of these data sets, it is systematically incorrect when predicting the correct output for $x$. \n",
    "\n",
    "A learning algorithm has high **variance** for a particular input $x$ if it predicts different output values when trained on different training sets. \n",
    "\n",
    "The prediction error of a learned classifier is related to the sum of the bias and the variance of the learning algorithm. \n",
    "\n",
    "Generally, there is a tradeoff between bias and variance. \n",
    "\n",
    "A learning algorithm with low bias must be \"flexible\" so that it can fit the data well. But if the learning algorithm is too flexible, it will fit each training data set differently, and hence have high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example of underfitting and overfitting \n",
    "\n",
    "The data generated from a quadratic function with noisy. We will try fitting several polynomial models of different order. The results presented here are of degree: 1, 2, 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "1.047 x + 7.871\n",
      "       2\n",
      "1.075 x - 0.02733 x - 0.5649\n",
      "          10            9           8          7          6         5\n",
      "0.001067 x  - 0.005188 x - 0.03521 x + 0.1653 x + 0.3842 x - 1.657 x\n",
      "          4         3         2\n",
      " - 1.651 x + 5.761 x + 3.566 x - 4.848 x - 1.092\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get x and y vectors\n",
    "n = 11\n",
    "x = np.linspace(-4, 5, n)\n",
    "np.random.RandomState(seed=20200505)\n",
    "y = x*x + stats.norm.rvs(loc=0.0, scale=1, size=n) \n",
    "\n",
    "# calculate polynomial degree 1\n",
    "z1 = np.polyfit(x, y, 1)\n",
    "f1 = np.poly1d(z1)\n",
    "print(f1)\n",
    "# calculate polynomial degree 2\n",
    "z2 = np.polyfit(x, y, 2)\n",
    "f2 = np.poly1d(z2)\n",
    "print(f2)\n",
    "# calculate polynomial degree 10\n",
    "z10 = np.polyfit(x, y, 10)\n",
    "f10 = np.poly1d(z10)\n",
    "print(f10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# calculate new x's and y's from fitted model\n",
    "x_new = np.linspace(x[0], x[-1], 500)\n",
    "y1 = f1(x_new)\n",
    "y2 = f2(x_new)\n",
    "y10 = f10(x_new)\n",
    "\n",
    "figure_polyfit, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(x_new, y1, label=\"poly d=1\")\n",
    "ax.plot(x_new, y2, label=\"poly d=2\")\n",
    "ax.plot(x_new, y10, label=\"poly d=10\")\n",
    "ax.scatter(x, y, s=80, label=\"data\")\n",
    "plt.xlabel('x', fontsize=16)\n",
    "plt.ylabel('y', fontsize=16)\n",
    "ax.legend(loc='upper center', fontsize=16)\n",
    "\n",
    "#plt.show()\n",
    "figure_polyfit.savefig('../image/figure_polyfit.png') # save the figure to file\n",
    "plt.close(figure_polyfit) # close the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../image/figure_polyfit.png\" width=\"1600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "1.14 x + 7.497\n",
      "        2\n",
      "0.9856 x + 0.1543 x - 0.2401\n",
      "            10            9           8           7           6\n",
      "-0.0003878 x  + 0.002285 x + 0.01091 x - 0.07199 x - 0.08327 x\n",
      "           5           4         3         2\n",
      " + 0.7026 x + 0.08401 x - 2.257 x + 1.615 x + 1.409 x - 0.7739\n"
     ]
    }
   ],
   "source": [
    "np.random.RandomState(seed=20200512)\n",
    "ya = x*x + stats.norm.rvs(loc=0.0, scale=1, size=n) \n",
    "\n",
    "# calculate polynomial degree 1\n",
    "z1a = np.polyfit(x, ya, 1)\n",
    "f1a = np.poly1d(z1a)\n",
    "print(f1a)\n",
    "# calculate polynomial degree 2\n",
    "z2a = np.polyfit(x, ya, 2)\n",
    "f2a = np.poly1d(z2a)\n",
    "print(f2a)\n",
    "# calculate polynomial degree 10\n",
    "z10a = np.polyfit(x, ya, 10)\n",
    "f10a = np.poly1d(z10a)\n",
    "print(f10a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# calculate new x's and y's from fitted model\n",
    "x_new = np.linspace(x[0], x[-1], 500)\n",
    "y1a = f1a(x_new)\n",
    "y2a = f2a(x_new)\n",
    "y10a = f10a(x_new)\n",
    "\n",
    "figure_polyfit_rnd, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(x_new, y1, label=\"poly d=1\")\n",
    "ax.plot(x_new, y1a, label=\"poly d=1*\")\n",
    "ax.plot(x_new, y10, label=\"poly d=10\")\n",
    "ax.plot(x_new, y10a, label=\"poly d=10*\")\n",
    "ax.scatter(x, y, s=80, label=\"data\")\n",
    "ax.scatter(x, ya, s=80, label=\"data*\")\n",
    "plt.xlabel('x', fontsize=16)\n",
    "plt.ylabel('y', fontsize=16)\n",
    "ax.legend(loc='upper center', fontsize=12)\n",
    "\n",
    "#plt.show()\n",
    "figure_polyfit_rnd.savefig('../image/figure_polyfit_rnd.png') # save the figure to file\n",
    "plt.close(figure_polyfit_rnd) # close the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../image/figure_polyfit_rnd.png\" width=\"1600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- In linear model, lines are very close to one another but far away from actual data. \n",
    "- On the other hand, higher degree polynomial curves follow data carefully but have high differences among them. \n",
    "\n",
    "Therefore, bias is high in linear and variance is high in higher degree polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Bias** and **Variance** help us in parameter tuning and deciding better fitted model among several built.\n",
    "\n",
    "- **Bias** is one type of error which occurs due to wrong assumptions about data such as assuming data is linear when in reality, data follows a complex function. \n",
    "- **Variance** gets introduced with high sensitivity to variations in training data. This also is one type of error since we want to make our model robust against noise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Definition\n",
    "\n",
    "Let f(x) be the function which our given data follows.\n",
    "\n",
    "We will build few models which can be denoted as $\\hat{f}(x)$. Each point on this function is a random variable having number of values equal to number of models. To correctly approximate the true function f(x), we take expected value of $\\hat{f}(x)$ : $E[\\hat{f}(x)]$.\n",
    "\n",
    "\\begin{align*}\n",
    "Bias &: f - E[\\hat{f}]\\\\\n",
    "Variance &: E\\left[\\left(\\hat{f} - E[\\hat{f}] \\right)^2\\right]\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### MSE\n",
    "The empirical error between target value and predicted value:\n",
    "\\begin{align*}\n",
    "MSE &= E\\left[ \\left(f - \\hat{f}\\right)^2\\right] \\\\\n",
    " &= E\\left[ f^2 - 2f\\hat{f} + \\hat{f}^2\\right] \\\\ \n",
    " &= f^2 E[1] - 2f E\\left[\\hat{f}\\right] + E\\left[\\hat{f}^2\\right] \\\\\n",
    " &= f^2 - 2f E\\left[\\hat{f}\\right] + E\\left[\\hat{f}^2\\right]\n",
    "\\end{align*}\n",
    "\n",
    "The quantity:\n",
    "\\begin{align*}\n",
    "\\text{bias}^2 + \\text{variance} &= \\left( f - E[\\hat{f}] \\right)^2 + E\\left[\\left(\\hat{f} - E[\\hat{f}] \\right)^2\\right] \\\\\n",
    " &=  f^2 - 2f E\\left[\\hat{f}\\right] + \\left(E\\left[\\hat{f}\\right]\\right)^2 + E\\left[ \\hat{f}^2\\right] - 2 E\\left[ \\hat{f}\\right]E\\left[ \\hat{f}\\right] + \\left(E\\left[\\hat{f}\\right]\\right)^2 \\\\ \n",
    " &= f^2 - 2f E\\left[\\hat{f}\\right] + E\\left[\\hat{f}^2\\right] \\\\\n",
    " &= MSE\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Important** thing to remember is bias and variance have trade-off\n",
    "\n",
    "In order to minimize error, we need to reduce both. \n",
    "\n",
    "This means that we want our model prediction to be close to the data (low bias) and ensure that predicted points don't vary much w.r.t. changing noise (low variance).\n",
    "\n",
    "<img src=\"../image/biasVarianceBalance.png\" width=\"800\">"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "ÂπªÁÅØÁâá",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
